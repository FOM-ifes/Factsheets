\documentclass[landscape,twocolumn,a4paper,8pt]{extarticle}

\usepackage{xspace}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage[a4paper]{geometry}
\usepackage[cm]{fullpage}
\usepackage{tabularx}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}} % linksbündig mit Breitenangabe
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}} % zentriert mit Breitenangabe
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash}p{#1}} % rechtsbündig mit Breitenangabe


\setlength\parindent{0pt}

\begin{document}

\title{Übersicht: Inferenzstatistik}
\author{Karsten Lübke}
\date{}
\maketitle

\raggedright

\section{Hintergrund}

$$\underbrace{\text{ Beobachteter Wert }}_{\text{Statistik}} = \underbrace{\text{ Wahrer Wert }}_{\text{Wert des Parameters}} + \text{ Verzerrung } + \text{ Rauschen }$$

\begin{itemize}
\item Beobachteter Wert, Statistik: z.\,B. Anteil in Stichprobe $p$, Mittelwert $\bar{x}$ usw.
\item Wahrer Wert, Parameter: z.\,B. Anteil in Population $\pi$, Mittelwert $\mu$ usw.
\end{itemize}

\textbf{Ziel:} Aussagen treffen, die über die Stichprobe hinausgehen -- und dabei berücksichtigen, dass Variation allgegenwärtig ist und Schlussfolgerungen unsicher.

\section{Punktschätzung}

Der Wert der Stichprobe wird häufig als \textbf{Punktschätzer} (engl.: (point) estimate) für den interessierenden Wert der Population verwendet, z.\,B.:

\begin{itemize}
\item Anteil (kategoriale Daten): Population $\pi$, Stichprobe $p$, Punktschätzer $\hat{\pi}=p$.
\item Arithmetischer Mittelwert (metrische Daten): Population $\mu$, Stichprobe $\bar{x}$, Punktschätzer $\hat{\mu}=\bar{x}$.
\item Korrelationskoeffizent (metrische Daten): Population $\rho$, Stichprobe $r$, Punktschätzer $\hat{\rho}=r$.
\end{itemize}

Das Symbol Dach ($\hat{}$) zeigt an, dass der unbekannte, wahre Wert geschätzt wurde. 

Punktschätzer sind Funktionen der Stichprobe.

\section{Konfidenzintervall}

Punktschätzer variieren mit der Stichprobe. 

\begin{itemize}
\item Der \textbf{Standardfehler} (engl.: standard error) $se$ beschreibt die Streuung (Standardabweichung) eines Schätzwertes, d.\,h. die Größe des \emph{Rauschens}. 

Z.\,B. für den arithmetischen Mittelwert $\bar{x}$: $se=\frac{sd}{\sqrt{n}}$, d.\,h., $se$ sinkt (unter sonst gleichen Umständen) mit steigendem $n$.

\item Ein \textbf{Konfidenzintervall}  gibt einen Bereich an, der den wahren, unbekannten Wert der Population mit einer gegebenen Sicherheit (z.\,B. $95\,\%=1-\alpha=100\,\%-5\,\%$) überdeckt, d.\,h., den Anteil der so konstruierten Konfidenzintervalle, die den Wert enthalten.

Häufig bei $n>30$ z.\,B. für den Mittelwert: $95\,\%$-KI für $\mu$: $\approx \bar{x} \pm 2 \cdot se = \bar{x} \pm 2 \cdot \frac{sd}{\sqrt{n}}.$
\end{itemize}


<<fig.align="center", out.width="0.8\\linewidth", fig.asp = 0.6, echo=FALSE, message = FALSE>>=
library(mosaic)
theme.fom <- theme_classic(22*1.04)
theme.fom <- theme.fom
theme_set(
  theme.fom  
)

set.seed(1896)
mosaic:::CIsim(n=100)
@


\section{Hypothesenprüfung}

\begin{itemize}
\item Die \textbf{Nullhypothese} $H_0$ ist in der Regel die, dass es keinen Unterschied/ keinen Zusammenhang gibt.

\item Anhand einer geeigneten \textbf{Teststatistik}  werden die Stichprobendaten zusammengefasst. Ist die Wahrscheinlichkeit einer mindestens so großen Abweichung unter $H_0$ (sehr) klein, wird diese verworfen, andernfalls nicht.

\item Der \textbf{p-Wert} gibt den Anteil der Stichproben an, die ein mindestens so extremes Ergebnis wie die beobachtete Stichprobe haben, wenn $H_0$ gelten würde.

Der p-Wert wird bestimmt, nachdem die Daten vorliegen.

\textbf{Achtung}: Der p-Wert sagt nicht aus, wie wahrscheinlich die $H_0$ bei den vorliegenden Daten ist oder ob das Ergebnis inhaltlich relevant ist.

\item Die \textbf{Alternativhypothese} $H_A$ (oder $H_1$) ist das Gegenteil der Nullhypothese. Die Rollen von $H_0$ und $H_A$ können nicht vertauscht werden.

Alternativen können einseitig, gerichtet (z.\,B. $\pi>\pi_0$ bzw. $\pi<\pi_0$) oder zweiseitig, ungerichtet (z.\,B. $\pi \neq \pi_0$) sein.

\item Das vorab festgelegte \textbf{Signifikanzniveau} $\alpha$, (üblich z.\,B. $\alpha=1\%, 5\%, 10\%$) eines Tests gibt die maximal zugebilligte (Irrtums-)wahrscheinlichkeit dafür an, $H_0$ zu verwerfen, obwohl $H_0$ gilt.

Damit können vorab kritische Werte der Verteilung unter $H_0$ bestimmt werden: Liegt der Wert der Teststatistik der Stichprobe außerhalb, wird $H_0$ verworfen, sonst nicht.

Ist der p-Wert $< \alpha$, so wird $H_0$ verworfen, ansonsten nicht. 
Wird die $H_0$ verworfen, so wird das Ergebnis als statistisch signifikant zum Niveau $\alpha$ bezeichnet.
\end{itemize}


\textbf{Fehlerarten}

\begin{table}[!htb]
\begin{tabular}{L{.3\columnwidth}|L{.3\columnwidth}L{.3\columnwidth}}
    & Testentscheidung \mbox{$H_0$ nicht verwerfen} &  Testentscheidung \mbox{$H_0$ verwerfen}\\ \hline
Realität: $H_0$  & Ok  & Fehler 1. Art ($\alpha$-Fehler) \\
Realität: $H_A$  & Fehler 2. Art ($\beta$-Fehler) & Ok \\
\end{tabular}
\end{table}


\subsection{Simulationsbasierte Inferenz}

\begin{itemize}
\item \textbf{Einfache Simulation}: Simuliere Verteilung einer Stichprobe unter der Annahme von $H_0$, z.\,B. $\pi_0=0.5$. 

\item \textbf{Permutationstest}: Simuliere zufällige Zuordnung. Simuliere Verteilung einer Statistik unter der Annahme, dass kein Unterschied vorliegt (Modell $H_0$), u.\,a. zur Bestimmung von p-Werten.

<<eval=FALSE>>=
do(oft) * statistik(y ~ shuffle(x), data = Daten)
@

\item \textbf{Bootstrap}: Simuliere zufälliges Ziehen einer Stichprobe. Schätze Verteilung einer Statistik der Stichprobe, u.\,a. zur Bestimmung von Standardfehlern oder Konfidenzintervallen.

<<eval=FALSE>>=
do(oft) * statistik(y ~ x, data = resample(Daten))
@
\end{itemize}

\end{document}
