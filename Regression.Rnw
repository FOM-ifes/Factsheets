\documentclass[landscape,twocolumn,a4paper,8pt]{extarticle}

\usepackage{xspace}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage[a4paper]{geometry}
\usepackage[cm]{fullpage}
\usepackage{tabularx}

\setlength\parindent{0pt}

\begin{document}

\title{Übersicht: Lineare Regression}
\author{Karsten Lübke}
\date{}
\maketitle

\raggedright

\section{Einfache lineare Regression} \label{Sec:ELR}

Modellierung:

$$\underbrace{y_i}_{Daten} = \underbrace{\beta_0 + \beta_1 \cdot x_i}_{Modell} + \underbrace{\epsilon_i}_{Rest}$$

Also 

$$y_i = f(x_i) = \beta_0 + \beta_1 \cdot x_i + \epsilon_i$$ 

Mit
\begin{itemize}
\item $\beta_0$: Achsenabschnitt
\item $\beta_1$: Steigung, d.h. die Änderung des Mittelwerts von $y$, wenn $x$ eine Einheit größer ist
\end{itemize}


Kleinste-Quadrate-Kriterium zur Schätzung von Achsenabschnitt und Steigung mit Hilfe einer Stichprobe: Schätze $\hat{\beta}_0$ und $\hat{\beta}_1$ so, dass die Quadratsumme der Residuen $\sum \hat{\epsilon}^2_i$ mit $\hat{\epsilon}_i = y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i)$ minmal ist. Ergebnis:
\begin{itemize}
\item $\hat{\beta}_1=\frac{s_{x,y}}{s^2_x}=\frac{s_y}{s_x}\cdot r_{x,y}$
\item $\hat{\beta}_0=\bar{y}-\hat{\beta}_1\cdot \bar{x}$
\end{itemize}

<<fig.align="center", out.width="0.8\\linewidth", fig.asp = 0.6, echo=FALSE, message = FALSE, warning = FALSE>>=
library(mosaic)
library(latex2exp)
theme.fom <- theme_classic(22*1.04)
theme.fom <- theme.fom
theme_set(
  theme.fom  
)

set.seed(1896)
n <- 15
x <- runif(n, -2, 5)
y <- -5 + 2*x + rnorm(n)
erglm <- lm(y~x)

intercept <- coef(erglm)[1]
slope <- coef(erglm)[2]

yhat <- predict(erglm, newdata = data.frame(x=2))
y0 <- mean(~y)
yh <- fitted(erglm)


gf_point(y ~ x) %>%
  gf_lims(y=c(-10,10)) %>%
  gf_lm(color = "#00998A") +
  annotate("segment", x = 0, xend = 0, yend = intercept, y = 0,
           color = "blue", arrow = arrow(length = unit(0.03, "npc"))) +
  annotate("segment", x = 2, xend = 3, yend = yhat , y = yhat ,
           color = "darkgrey", arrow = arrow(length = unit(0.03, "npc"))) +
  annotate("segment", x = 3, xend = 3, yend = yhat + slope , y = yhat ,
           color = "blue", arrow = arrow(length = unit(0.03, "npc"))) +
  annotate("text", x = -0.25, y = intercept+slope, size = 6,
           label = TeX("$\\hat{\\beta}_0$", output='character'), parse=TRUE) +
  annotate("text", x = 3.25, y = yhat + slope/2, size = 6,
           label = TeX("$\\hat{\\beta}_1$", output='character'), parse=TRUE) 
@


Aber: 
$$\underbrace{\hat{\beta}}_{\text{Statistik}} = \underbrace{\beta}_{\text{Wert des Parameters}} + \text{ Verzerrung } +  \text{ Rauschen }$$

Das \textbf{Bestimmtheitsmaß} $R^2$ gibt den Anteil der im Modell erklärten Variation von $y$ an: 
$$R^2=\frac{\sum_{i=1}^n (\hat{y}_i-\bar{y})^2}{\sum_{i=1}^n (y_i-\bar{y})^2}= 1-\frac{\sum_{i=1}^n (y_i-\hat{y}_i)^2}{\sum_{i=1}^n (y_i-\bar{y})^2}$$
mit $\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i$.

\subsubsection*{Bedingungen}

\begin{itemize}
\item Kein nicht-linearer Zusammenhang zwischen $x$ und $y$,
\item keine (einflussreichen) Ausreißer,
\item Fehler $\epsilon$ unabhängig (d.h. keine (Auto-) Korrelation), identisch (insbesondere konstante Varianz), normalverteilt.
\end{itemize}

\section{Multiple Regression}

$$y_i = \beta_0 + \beta_1 \cdot x_{i1} + \beta_2 \cdot x_{i2} + \ldots + \beta_p \cdot x_{ip} + \epsilon_i$$

Bestimmtheitsmaß, Bedingungen etc. siehe Abschnitt \ref{Sec:ELR}.

\newpage

\section{Interpretation \texttt{R} Ausgabe}

\subsection*{\texttt{summary(erglm)}}

$x1$ metrisch, $x2$ kategorial mit zwei Ausprägungen, $A$ und $B$:

<<echo=FALSE>>=
set.seed(1896)

n <- 100
x1 <-rnorm(n, mean = 50, sd = 10)
x2 <- sample(c("A","B"), n, replace = TRUE)

y <- 20 + 2 *x1 - 5*ifelse(x2=="b",1,0)
y <- y + rnorm(n, sd = sd(y)/2)

erglm <- lm(y ~ x1+x2)
summary(erglm)
@

\subsubsection*{Besonders relevant:}

Tabelle \texttt{Coefficients} -- Spalte \texttt{Estimate} gibt die geschätzten Koeffizienten des Modells der Stichprobe an. Interpretation unter sonst gleichen Umständen.
\begin{itemize}
\item Zeile \texttt{(Intercept)}: Geschätzter Achsenabschnitt $\hat{\beta}_0=\Sexpr{round(coef(erglm)[1],5)}$. Mittelwert von $y$, wenn $x1=0$ und $x2=A$ ist.
\item Zeile \texttt{x1}: Geschätzte Steigung $\hat{\beta}_{x1}=\Sexpr{round(coef(erglm)[2],5)}$. Modellierte Änderung des Mittelwerts von $y$, wenn $x1$ eine Einheit größer beobachtet wird.
\item Zeile \texttt{x2B}: Geschätzte Änderung $\hat{\beta}_{x2B}=\Sexpr{round(coef(erglm)[3],5)}$. Modellierte Änderung des Mittelwerts von $y$, wenn $x2=B$ (anstelle von $x2=A$) beobachtet wird.
\end{itemize}

$$\hat{y}_i = \Sexpr{round(coef(erglm)[1],5)} + \Sexpr{round(coef(erglm)[2],5)} \cdot x1_i \Sexpr{round(coef(erglm)[3],5)} \cdot \begin{cases} 1 &: x2_i = B \\ 0 &: x2_i = \text{sonst} \end{cases}$$

Tabelle \texttt{Coefficients} -- Spalte \texttt{Pr(>|t|)} gibt die mit Hilfe mathematischer Statistik bestimmten p-Werte für die jeweilige Nullhypothese $H_0: \beta_j=0$ an.
\begin{itemize}
\item Zeile \texttt{(Intercept)}: p-Werte $\Sexpr{ifelse(summary(erglm)$coefficients[,4]<2e-16,"<2e-16",round(summary(erglm)$coefficients[,4],5))[1]}$. Geschätzter Achsenabschnitt statistisch erkennbar von $0$ verschieden. (Statistisch signifikant zum Niveau $\alpha=5\,\%$.)
\item Zeile \texttt{x1}: p-Wert $\Sexpr{ifelse(summary(erglm)$coefficients[,4] < 2e-16, "<2e-16", round(summary(erglm)$coefficients[,4],5))[2]} = 2 \cdot 10^{-16}$. Geschätzte Steigung statistisch erkennbar von $0$ verschieden. (Statistisch signifikant zum Niveau $\alpha=5\,\%$.)
\item Zeile \texttt{x2B}: p-Wert $\Sexpr{ifelse(summary(erglm)$coefficients[,4]<2e-16,"2e-16",round(summary(erglm)$coefficients[,4],5))[3]}$. Geschätzte Steigung statistisch nicht erkennbar von $0$ verschieden. (Statistisch nicht signifikant zum Niveau $\alpha=5\,\%$.)
\end{itemize}


\texttt{Multiple R-squared}: Bestimmtheitsmaß $R^2 = \Sexpr{round(rsquared(erglm),4)}$. $\Sexpr{round(rsquared(erglm),2)*100}\,\%$ der Variation von $y$ kann durch $x1$ und $x2$ linear modelliert werden.


\subsection*{\texttt{confint(erglm)}}

Ergänzend zu den p-Werten Ausgabe der Konfidenzintervalle:

<<echo = FALSE>>=
confint(erglm)
KIs <- confint(erglm)
@

Mit einer Sicherheit $1-\alpha = 95\,\%$ überdeckt der Bereich  

\begin{itemize}
  \item für \texttt{x1}: $\Sexpr{round(KIs["x1", 1], 4)}$ bis $\Sexpr{round(KIs["x1", 2], 4)}$ den unbekannten Wert der Steigung von \texttt{x1} in der Population;
  \item für \texttt{x2B}: $\Sexpr{round(KIs["x2B", 1], 4)}$ bis $\Sexpr{round(KIs["x2B", 2], 4)}$ den unbekannten Wert der Änderung des Mittelwerts von $y$ in der Population, wenn \texttt{B} statt \texttt{A} beobachtet wird.
\end{itemize}

Die angegebene Sicherheit bezieht sich auf das Verfahren: bei wiederholter Stichprobenziehung Anteil der so konstruierten Konfidenzintervalle, die den wahren, festen Wert in der Population enthalten.

\end{document}
